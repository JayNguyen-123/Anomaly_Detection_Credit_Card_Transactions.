{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZJwYw3MxO9uKhS2lIiw6r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayNguyen-123/Anomaly_Detection_Credit_Card_Transactions./blob/main/Anomaly_Detection_Credit_card_Transactions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Anomaly Detection\n",
        "- Anomaly detection is a critical component of data analysis across various domains such as financial, cybersecurity, healthcare and more.\n",
        "- Anomalies, often referred to as outliers or anomalies, are data points or observations that significantly deviate from the expected or normal behavior within a dataset. These deviations can be caused by various factors, such as errors in data collection, rare events, system malfunctions, or even intentional fraudulent activities.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vxf4d3PXg2dR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyod\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyod.models.xgbod import XGBOD\n",
        "from pyod.models.pca import PCA\n",
        "from pyod.models.iforest import IForest\n",
        "from pyod.models.cblof import CBLOF\n",
        "from pyod.models.hbos import HBOS\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (precision_recall_curve, average_precision_score, roc_auc_score)\n",
        "\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQOBuxAQhaO9",
        "outputId": "b9b3e3a9-e7ae-48ae-a31e-7d3a37dbba5d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyod\n",
            "  Downloading pyod-2.0.5-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/46.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from pyod) (1.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from pyod) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.12/dist-packages (from pyod) (2.0.2)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.12/dist-packages (from pyod) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /usr/local/lib/python3.12/dist-packages (from pyod) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from pyod) (1.6.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51->pyod) (0.43.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.0->pyod) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyod) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyod) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyod) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyod) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyod) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyod) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyod) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyod) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->pyod) (1.17.0)\n",
            "Downloading pyod-2.0.5-py3-none-any.whl (200 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.6/200.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyod\n",
            "Successfully installed pyod-2.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df = pd.read_csv('/content/creditcard.csv')\n",
        "X, y = df.drop(columns='Class').values, df['Class'].values\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Fraud rate (%): {y.mean()*100:.4f}\")\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW21roFQl612",
        "outputId": "1a77039c-7054-4ece-82a5-4b3f2e3f783c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (284807, 30)\n",
            "Fraud rate (%): 0.1727\n",
            "Training set: 199364 samples\n",
            "Test set: 85443 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_supervised_labels(y_train, supervision_ratio=0.01):\n",
        "  \"\"\" Create supervised labels on supervision ratio.\"\"\"\n",
        "\n",
        "  fraud_indices = np.where(y_train == 1)[0]\n",
        "  n_labeled_fraud = int(len(fraud_indices) * supervision_ratio)\n",
        "\n",
        "  # Randomly select labeled samples\n",
        "  labeled_fraud_idx = np.random.choice(fraud_indices,\n",
        "                                       n_labeled_fraud, replace=False)\n",
        "\n",
        "  # Create labels\n",
        "  y_labels = np.zeros_like(y_train)\n",
        "  y_labels[labeled_fraud_idx] = 1\n",
        "\n",
        "  # Calculate how many true are in the \"unlabeled\" set\n",
        "  unlabeled_fraud_count = len(fraud_indices) - n_labeled_fraud\n",
        "\n",
        "  return y_labels, labeled_fraud_idx, unlabeled_fraud_count\n",
        ""
      ],
      "metadata": {
        "id": "yWJIBKuGnOJ_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "  \"\"\"Evaluate a single model and return metrics.\"\"\"\n",
        "\n",
        "  # Get anomaly scores\n",
        "  scores = model.decision_function(X_test)\n",
        "\n",
        "  # Calculate metrics\n",
        "  auc_pr = average_precision_score(y_test, scores)\n",
        "\n",
        "  return {\n",
        "      'model': model_name,\n",
        "      'auc_pr': auc_pr,\n",
        "      'scores': scores\n",
        "  }"
      ],
      "metadata": {
        "id": "RnJ7Yuz6p8o3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model, X_test, y_test, model_name):\n",
        "  \"\"\"Evaluate a single model and return metrics.\"\"\"\n",
        "  # Get anomaly scores\n",
        "  scores = model.decision_function(X_test)\n",
        "\n",
        "  # Calculate metrics\n",
        "  auc_pr = average_precision_score(y_test, scores)\n",
        "\n",
        "  return {\n",
        "      'model': model_name,\n",
        "      'auc_pr': auc_pr,\n",
        "      'scores': scores\n",
        "  }"
      ],
      "metadata": {
        "id": "z3H07iOUoXHZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unsupervised Anomaly Detection\n",
        "models = {\n",
        "    'IsolationForest': IForest(random_state=42),\n",
        "    'CBLOF': CBLOF(),\n",
        "    'HBOS': HBOS(),\n",
        "    'PCA': PCA(),\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    model.fit(X_train)\n",
        "    result = evaluate_model(model, X_test, y_test, name)\n",
        "    print(f\"{name:20} - AUC-PR: {result['auc_pr']:.4f}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0WhOsx7o6vf",
        "outputId": "e5afc038-b612-4058-d0c3-54ebc882d07a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training IsolationForest...\n",
            "IsolationForest      - AUC-PR: 0.1497\n",
            "Training CBLOF...\n",
            "CBLOF                - AUC-PR: 0.1521\n",
            "Training HBOS...\n",
            "HBOS                 - AUC-PR: 0.2488\n",
            "Training PCA...\n",
            "PCA                  - AUC-PR: 0.1411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- With zero hyperparameter tuning, none of the algorithms delivered very promising results, as their AUCPR values (~0.15–0.25) may fall short of the very high precision/recall often required in fraud-detection settings.\n",
        "- However, we should note that, unlike AUC-ROC, which has a baseline value of 0.5, the baseline AUCPR depends on the prevalence of the positive class. For our current dataset, since only 0.17% of the samples are fraud, a naive classifier that guesses randomly would have an AUCPR ≈ 0.0017. In that sense, all detectors already outperform random guessing by a wide margin.\n"
      ],
      "metadata": {
        "id": "fWs8Jkdeq1A-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBOD Approach\n",
        "- XGBOD(Extreme Gradient Boosting Outliner Detection) is a semi-supervised framework designed for high-perfromance outliner detection.\n",
        "- It combines the strengths of both supervised and unsupervised learning methods to enhance the detection of outliers.\n"
      ],
      "metadata": {
        "id": "susRb-FFlsNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "supervision_ratios = [0.01, 0.02, 0.05, 0.1, 0.15, 0.2]\n",
        "\n",
        "for ratio in supervision_ratios:\n",
        "  # Create supervised labels\n",
        "  y_labels, labeled_fraud_idx, unlabeled_fraud_count = create_supervised_labels(y_train, ratio)\n",
        "\n",
        "  total_fraud = sum(y_train)\n",
        "  labeled_fraud = sum(y_labels)\n",
        "\n",
        "  print(f\"Know frauds (labeled as 1): {labeled_fraud}\")\n",
        "  print(f\"Hidden frauds in 'normal' data: {unlabeled_fraud_count}\")\n",
        "  print(f\"Total samples treated as normal: {len(y_train) - labeled_fraud}\")\n",
        "  print(f\"Fraud contamination in 'normal' set: {unlabeled_fraud_count / (len(y_train) - labeled_fraud) * 100:.3f}%\")\n",
        "\n",
        "  # Train XGBOD models\n",
        "  xgbod = XGBOD(estimator_list=[PCA(), CBLOF(), IForest(), HBOS()],\n",
        "                random_state=42,\n",
        "                n_estimators=200, learning_rate=0.1,\n",
        "                eval_metric='aucpr')\n",
        "\n",
        "  xgbod.fit(X_train, y_labels)\n",
        "  result = evaluate_model(xgbod, X_test, y_test, f\"XGBOD_ratio_{ratio:.3f}\")\n",
        "  print(f\"xgbod - AUC-PR: {result['auc_pr']:.4f}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do22-cldrDmj",
        "outputId": "5a2fbd85-8d76-475b-9944-231f62111b38"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Know frauds (labeled as 1): 3\n",
            "Hidden frauds in 'normal' data: 341\n",
            "Total samples treated as normal: 199361\n",
            "Fraud contamination in 'normal' set: 0.171%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [15:16:52] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgbod - AUC-PR: 0.5164\n",
            "Know frauds (labeled as 1): 6\n",
            "Hidden frauds in 'normal' data: 338\n",
            "Total samples treated as normal: 199358\n",
            "Fraud contamination in 'normal' set: 0.170%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [15:17:04] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgbod - AUC-PR: 0.4546\n",
            "Know frauds (labeled as 1): 17\n",
            "Hidden frauds in 'normal' data: 327\n",
            "Total samples treated as normal: 199347\n",
            "Fraud contamination in 'normal' set: 0.164%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [15:17:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgbod - AUC-PR: 0.6606\n",
            "Know frauds (labeled as 1): 34\n",
            "Hidden frauds in 'normal' data: 310\n",
            "Total samples treated as normal: 199330\n",
            "Fraud contamination in 'normal' set: 0.156%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [15:17:29] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgbod - AUC-PR: 0.6965\n",
            "Know frauds (labeled as 1): 51\n",
            "Hidden frauds in 'normal' data: 293\n",
            "Total samples treated as normal: 199313\n",
            "Fraud contamination in 'normal' set: 0.147%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [15:17:41] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgbod - AUC-PR: 0.7161\n",
            "Know frauds (labeled as 1): 68\n",
            "Hidden frauds in 'normal' data: 276\n",
            "Total samples treated as normal: 199296\n",
            "Fraud contamination in 'normal' set: 0.138%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [15:17:54] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgbod - AUC-PR: 0.7237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supervised Learning\n",
        "for ratio in supervision_ratios:\n",
        "\n",
        "  # Create supervised labels\n",
        "  y_label, labeled_fraud_idx, unlabeled_fraud_count = create_supervised_labels(y_train, ratio)\n",
        "\n",
        "  clf = XGBClassifier(n_estimators=200, random_state=42,\n",
        "                      learning_rate=0.1, eval_metric='aucpr')\n",
        "  clf.fit(X_train, y_label)\n",
        "\n",
        "  y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
        "  auc_pr = average_precision_score(y_test, y_pred_proba)\n",
        "  print(f\"XGBoost - AUC-PR: {auc_pr:.4f}\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zIbagmEm1Bu",
        "outputId": "e1e73eb3-08c6-4860-82bb-5b3ee4bed441"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost - AUC-PR: 0.4786\n",
            "XGBoost - AUC-PR: 0.4202\n",
            "XGBoost - AUC-PR: 0.6502\n",
            "XGBoost - AUC-PR: 0.5564\n",
            "XGBoost - AUC-PR: 0.7312\n",
            "XGBoost - AUC-PR: 0.6318\n"
          ]
        }
      ]
    }
  ]
}